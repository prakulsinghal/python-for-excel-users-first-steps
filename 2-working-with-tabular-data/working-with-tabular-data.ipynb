{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with tabular data\n",
    "\n",
    "## Introducing `numpy`\n",
    "\n",
    "In the last module you saw some of the limitations for quick quantiative analysis using built-in Python functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's hard to calculate on lists!\n",
    "my_list = [4,1,5,2]\n",
    "my_list * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately you also learned about packages -- they'll come to our rescue!\n",
    "\n",
    "Let's store these same numbers in what's called a `numpy` *array*. \n",
    "\n",
    "This involves importing the `numpy` package. \n",
    "\n",
    "`numpy` is short for \"numerical Python.\"\n",
    "\n",
    "Generally when we are using a package for the first time, we need to do one of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install numpy\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `numpy` was installed already when we installed `pandas`.\n",
    "\n",
    "We *do* still need to import `numpy` before using it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `numpy.array()` to create an array.\n",
    "\n",
    "Arrays are collections of data enclosed in brackets `[]`. Unlike with lists, all elements of the array *need to be of the same type*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array\n",
    "my_array = numpy.array([4,1,5,2])\n",
    "print(my_array)\n",
    "print(type(my_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of type coercion\n",
    "my_coerced_array = numpy.array([1,2,3,'Boo!'])\n",
    "print(my_coerced_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert our list to an array.\n",
    "\n",
    "Lists and arrays may *look* the same to you, but they are of different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_list)\n",
    "my_list_to_array = numpy.array(my_list)\n",
    "print(my_list_to_array)\n",
    "\n",
    "print(type(my_list))\n",
    "print(type(my_list_to_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` arrays work in many ways like ranges of a spreadsheet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Isn't this what you were expecting earlier?\n",
    "print(my_array)\n",
    "print(my_array*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what we're seeing, we may want to be calling for `numpy` *quite* often. \n",
    "\n",
    "Let's look at a cool \"hack\" for doing so...\n",
    "\n",
    "### Aliasing modules\n",
    "\n",
    "Remember that each time we use a function or method associated with `numpy`, we need to tell Python where to look for it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another array...\n",
    "my_other_array = numpy.array([4,16,25,100])\n",
    "\n",
    "# numpy has a square root function of its own...\n",
    "numpy.sqrt(my_other_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am already getting sick of typing `numpy` each time I want to use something from it! Can't we make this easier?\n",
    "\n",
    "Yes. Yes, we can.\n",
    "\n",
    "Turns out we can temporarily rename, or *alias*, the `numpy` module when we import it. We will use the format:\n",
    "\n",
    "\n",
    "```\n",
    "import [name of module] as [alias]\n",
    "```\n",
    "\n",
    "`np` is a popular alias for `numpy`. Rather than calling for `numpy` each time you are using code from that module, you can simply type `np`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias numpy on import\n",
    "import numpy as np\n",
    "\n",
    "# Create another array...\n",
    "my_other_array = np.array([4,16,25,100])\n",
    "\n",
    "# numpy has a square root function of its own...\n",
    "np.sqrt(my_other_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill\n",
    "\n",
    "Take a shot at assigning an array and finding its square root using this aliasing method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and alias the module\n",
    "\n",
    "import ___ ___ ___\n",
    "\n",
    "# Create an array\n",
    "my_new_array = ___.___([36, 49, 64, 81])\n",
    "\n",
    "# Take its square root\n",
    "np.___(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Aliasing saved you some keystrokes, huh?\n",
    "\n",
    "![Life hackz](images/life-hackz.gif)\n",
    "\n",
    "## Accessing and reshaping arrays\n",
    "\n",
    "Python indexes *everything* at zero, not just lists. This includes `numpy` arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_array = np.array([4,1,5,2])\n",
    "\n",
    "# Access first element of the array\n",
    "print(my_array[1])\n",
    "\n",
    "# Oh sorry... NOW I'm accessing the first element! ü§¶‚Äç‚ôÇÔ∏è\n",
    "print(my_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've already sweated through zero-based indexing, so let's move on... to two-dimensional arrays. \n",
    "\n",
    "(You will see that you'll never truly escape zero-based indexing in Python, however... üòº)\n",
    "\n",
    "## Two-dimensional arrays in `numpy`\n",
    "\n",
    "So far, we have been working on one-dimensional sets of data. \n",
    "\n",
    "You can think of this as data being in one row or column of your workbook.\n",
    "\n",
    "But what if we wanted to mix that up? \n",
    "\n",
    "![Illustration of numpy arrays](images/numpy-arrays.png)\n",
    "\n",
    "\n",
    "\n",
    "Source: Nunez-Iglesias, Juan, St√©fan Van Der Walt, and Harriet Dashnow. *Elegant SciPy: The Art of Scientific Python.* O'Reilly Media, 2017.\n",
    "\n",
    "\n",
    "`numpy` can create three-dimensional arrays, but let's focus on two: this is a familiar way to shape data as it's how data is often is stored in spreadsheets (as rows and columns).\n",
    "\n",
    "\n",
    "We can create a two-dimensional array in `numpy` with the `array()` function. This time we will place each 'row' of the array inside its own set of brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a two-dimensional array with `np.array()`\n",
    "\n",
    "my_2d_array = np.array([[3,4,1],[2,5,0]])\n",
    "print(my_2d_array)\n",
    "print(type(my_2d_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also re-shape an existing one-dimensional array into a two-dimensional array using `np.reshape()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-dimensional array\n",
    "my_array = np.array([1,2,3,4,5,6])\n",
    "print(my_array)\n",
    "\n",
    "# Let's make a two-dimensional, 2 x 3 array\n",
    "my_reshaped_array = np.reshape(my_array, (2, 3))\n",
    "print(my_reshaped_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-dimensional array is starting to look like the kind of dataset that you might actually work with as a spreadsheet user, with rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting our arrays\n",
    "\n",
    "Variables in Python carry different `attributes` which we can find using the format \n",
    "\n",
    "`variable.attribute`\n",
    "\n",
    "\n",
    "Some attributes we can use to learn more about our `numpy` arrays are:\n",
    "\n",
    "`shape`: gives us the dimensions of the array.  \n",
    "`size`: gives us the number of elements of the array.   \n",
    "`dtype`: gives us the data type of the elements of the array. Remember that all elements of a `numpy` array must be of the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(my_reshaped_array.shape)\n",
    "print(my_reshaped_array.size)\n",
    "print(my_reshaped_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing our 2-dimensional arrays\n",
    "\n",
    "Remember when I said that zero-based indexing never really goes away? I wasn't kidding. \n",
    "\n",
    "Now we have to index on *two* counts: the row and the column. Our indexing of two-dimensional `numpy` arrays will look like this \n",
    "\n",
    "`np_array[row_number, column_number]`\n",
    "\n",
    "Some examples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(my_reshaped_array)\n",
    "\n",
    "# Get the value in first row, first column\n",
    "# Never forget zero-based indexing!\n",
    "my_reshaped_array[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the second-last row/second-last column?\n",
    "my_reshaped_array[-2,-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to use slicing to retrive data from multiple rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from first through second rows and columns\n",
    "my_reshaped_array[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about up through the second row and second column?\n",
    "my_reshaped_array[:2,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRILL\n",
    "\n",
    "Practice your `numpy` skills by operating on a large array. \n",
    "\n",
    "I will get you started; complete the operations based on what the comments are asking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't worry about this part -- I am reading the file into Python.\n",
    "# You will learn how to read files into Python in the next unit. \n",
    "my_array = np.genfromtxt('numpy-drill.csv')\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of this array?\n",
    "# This also tells us how many dimensions there are --\n",
    "# one number means one dimension\n",
    "my_array.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is its datatype?\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape this result into a 10x10 array\n",
    "my_array = np.reshape(___, ___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of our array now?\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the sqrt of this array\n",
    "my_array = np.___(___)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the element in the fourth row\n",
    "# and second column of the array\n",
    "my_array___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions about `numpy`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with `pandas`\n",
    "\n",
    "When you think of \"tabular data\" in Python, think of `pandas`. \n",
    "\n",
    "This package is built on top of `numpy`, but brings some extra functionalities for us. \n",
    "\n",
    "Similarly to `numpy`, `pandas` contains data structure of different dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas` Series\n",
    "\n",
    "These are one-dimensional data structures in `pandas`. \n",
    "\n",
    "We won't spend too much time analyzing these, but it's important to know that `pandas` will by default convert any one-dimensional data structure into a Series. \n",
    "\n",
    "*Notice the zero-based index? We'll get to that in a bit.*\n",
    "\n",
    "![pandas Series](images/series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "\n",
    "We will focus on the `pandas` DataFrame, which is a two-dimensional, tabular data structure with labeled rows and columns. Below is an example:\n",
    "\n",
    "![`pandas` DataFrame example](images/dataframe.png)\n",
    "\n",
    "\n",
    "*Look familiar?* This is very much the way we often store data in a spreadsheet.\n",
    "\n",
    "One key difference between `numpy` arrays and  `pandas` DataFrames is that the columns of DataFrames can be of different data types:\n",
    "\n",
    "![DataFrame column data types](images/datatypes.png)\n",
    "\n",
    "This is a *lot* like a spreadsheet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing `pandas`\n",
    "\n",
    "Same as with `numpy`, we will need to call in `pandas` each time we want to use it.\n",
    "\n",
    "Similarly to `numpy`, it is common to *alias* `pandas` when we import it. This alias usually takes the form:\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "Go ahead and try it yourself in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pandas into our session\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames\n",
    "\n",
    "There are several ways to create a DataFrame. We could, for example, convert a `numpy` array into one, using the [`DataFrame` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create our array\n",
    "numpy_data = np.array([[1,2,3], [4,5,6]])\n",
    "\n",
    "# Convert into a DataFrame\n",
    "df = pd.DataFrame(data=numpy_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, our DataFrame includes column *names* and row *index labels*... **starting at zero**!\n",
    "\n",
    "![labelled image of DataFrames](images/dataframe-labelled.png)\n",
    "\n",
    "It's common to keep the index labels as numeric, but to name the columns. Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our array\n",
    "numpy_data = np.array([[1,2,3], [4,5,6]])\n",
    "\n",
    "# Convert into a DataFrame,# name the columns\n",
    "df = pd.DataFrame(data=numpy_data, columns=['Column A','Column B','Column C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data into `pandas`\n",
    "\n",
    "While it's possible to create a DataFrame from scratch or from an existing data structure (like a `numpy` array), you'll more likely do by importing data from an outside source. \n",
    "\n",
    "`pandas` can create DataFrames from practically any data format, including SQL databases and HTML. But let's focus on `csv` files and Excel workbooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from `csv` files\n",
    "\n",
    "We can import a `csv` file as a DataFrame with `read_csv()`.\n",
    "\n",
    "There are a *lot* of [optional arguments to provide `read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html), but we *must* provide a file path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interlude: file paths and directories\n",
    "\n",
    "It can sometimes be tricky to locate *where* a file is located to read it into Python.\n",
    "\n",
    "By default, the file path you specify needs to be *relative to* your working directory. If you aren't sure that working directory is set, you can check with `os.getcwd()`. \n",
    "\n",
    "You will need to run `import os` first (This is part of the Python standard library.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# What folder am I operating in on my computer?\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the `state-populations.csv` file is located in the `data` subfolder of this directory, so we can find it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the state-populations file that exists in the data folder\n",
    "pd.read_csv('data/state-populations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[For more on how to work with files and directories in Python, check out this book chapter](https://learning.oreilly.com/library/view/automate-the-boring/9781098122584/xhtml/ch09.xhtml)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice we were able to read this into Python... but to do much of anything with it, we'll need to assign it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv as DataFrame, assign to variable\n",
    "state_pop = pd.read_csv('data/state-populations.csv')\n",
    "\n",
    "# Now I can refer to the variable and operate on it...\n",
    "# This one isn't real helpful üòº\n",
    "state_pop * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from Excel\n",
    "\n",
    "We'll now read in a file `state-populations.xlsx`, also located in the `data` folder.\n",
    "\n",
    "\n",
    "Reading Excel workbooks into DataFrames will work similar to `csv` files. \n",
    "\n",
    "This time, we'll use `read_excel()`. \n",
    "\n",
    "Once again, there are [lots of optional arguments](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html), but we must provide a file path: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our data\n",
    "state_pop = pd.read_excel('data/state-populations.xlsx')\n",
    "state_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our workbook contains multiple worksheets and we want to read specific one(s), we would specify the `sheet_name` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the `populations` worksheet\n",
    "state_pop = pd.read_excel('data/state-populations.xlsx', sheet_name='populations')\n",
    "print(state_pop)\n",
    "\n",
    "# There is also a `readme` worksheet\n",
    "readme = pd.read_excel('data/state-populations.xlsx',sheet_name='readme')\n",
    "print(readme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That second worksheet doesn't look much like a table of data... but `pandas` did its best to make it so! \n",
    "\n",
    "This is a good reminder that DataFrames will always be two-dimensional structures where all the rows in a given column are of the same data type, but different columns can be of different data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for reading data from Excel. \n",
    "\n",
    "**If you are interested in using Python to automate the creation of Excel workbooks, check out my OLT session on \"Python-Powered Excel.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from Google Sheets\n",
    "\n",
    "For many users, spreadsheets mean Google Sheets. \n",
    "\n",
    "It is possible to read DataFrames from Google Sheets but it requires using Google's API. Due to that added setup, we will skip for this workshop.\n",
    "\n",
    "[For instructions on reading from Google Sheets, check out this blog post.](https://towardsdatascience.com/accessing-google-spreadsheet-data-using-python-90a5bc214fd2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our DataFrame\n",
    "\n",
    "*Success*! Our data has been read in and assigned to a variable. Now let's get to know our data. \n",
    "\n",
    "We can of course get a start with `print()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(state_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is a *lot* of rows to look through. It's so much that Python doesn't even print all of them! You could [change the options](https://dev.to/chanduthedev/how-to-display-all-rows-from-data-frame-using-pandas-dha) to print all rows, but that's really not an effective way to size up our DataFrame. \n",
    "\n",
    "Instead, let's use the below methods and attributes to explore more efficiently:\n",
    "\n",
    " \n",
    "\n",
    "| Method/attribute | Returns                                                         |\n",
    "| ---------------- | --------------------------------------------------------------- |\n",
    "| `df.info()`      | Column names with their data type and number of complete values |\n",
    "| `df.columns`     | Column names                                                    |\n",
    "| `df.dtypes`      | Data types                                                      |\n",
    "| `df.shape`       | Dimensions (# rows by # columns)                                |\n",
    "| `df.head()`      | First 5 rows                                                    |\n",
    "| `df.tail()`      | Last 5 rows                                                     |\n",
    "| `df.describe()`  | Descriptive statistics                                          |\n",
    "\n",
    "\n",
    "`df` is a common stand-in for a generic DataFrame which you'll often see in examples. \n",
    "\n",
    "Our DataFrame is named `state_pop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Return column names, data types and number of complete values\n",
    "state_pop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types in `pandas` work a little differently than in base Python. For example, string types are classified as `object`. [For more on how `pandas` handles data types, check out this blog post](https://pbpython.com/pandas_dtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return column names\n",
    "state_pop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return data types\n",
    "state_pop.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return shape (no. of rows, no. of columns)\n",
    "state_pop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first 5 rows\n",
    "state_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first 12 rows\n",
    "state_pop.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last 5 rows\n",
    "state_pop.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics\n",
    "state_pop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRILL\n",
    "\n",
    "Practice reading in and exploring the two files in the `practice` folder.\n",
    "\n",
    "1. `largest-us-cities.csv`: Find the data types and dimensions of this DataFrame. Also print out the first five rows.\n",
    "2. `chicago-big-ten.xlsx`: The worksheet you're interested in is called `alumni`. Get the column names and run the descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on reading and exploring data in `pandas`! In the following sections we'll look at manipulating DataFrames and then visualizing the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
